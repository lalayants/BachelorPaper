Алгоритм ByteTrack \cite{zhang2022bytetrack} был представлен в 2022 году и сразу же завоевал первые позиции по качеству отслеживания объектов на изображениях на основе метрик MOTA, HOTA и IDF1.
До представления этого алгоритма, методы в основном основывались на работе только на показаниях детектора с высокой степенью уверенностью. Авторы же предложили способ получить преимущество, используя так же показания, в которых детектор не очень уверен.

На вход алгоритма поступают:
\begin{itemize}
    \item[--] видеоизображения, на которых предстоит провести отслеживание объектов;
    \item[--] детектор, который будет проводить детектирование объектов интересов;
    \item[--] граничная степень уверенности детектора \(\tau\). 
\end{itemize}
Выходом алгоритма являются получившиеся траектории. 

В ходе своей работы алгоритм сначала инициализирует массив траекторий для каждого найденного объекта. 
Затем в цикле для каждого кадра он получает набор пар область интереса-степень уверенности от детектора.
Полученные пары разбиваются на две группы: с высокой степенью уверенности большей \(\tau\) и с низкой. 
После этого для ранее найденных траекторий с помощью фильтра Калмана строится догадка об их положение на новом кадре.

Теперь начитается первый этап сопоставления. Для каждого объекта из группы с высокой степенью уверенности алгоритм подбирает близкую траекторию на основе метрики похожести. В ее роли может выступать как IoU (англ. Intersection over Union -- отношение площади пересечения к площади объединения двух объектов), так и ReID модель. 

На втором этапе сопоставления, для оставшихся траекторий, которым не нашлось объекта на первом этапе, производится попытка сопоставить объект из группы с низкой степенью уверености. На этом этапе рекомендуется использовать IoU, так как зачастую такие объекты смазаны или имеют какие-то перекрытия с другими, а потому ReID модели дают ненадежный результат.

Оставшиеся траектории помещаются в буфер потерянных траекторий. Если они находятся в этом буфере больше, чем какое-то количество итераций алгоритма (как правило 30 кадров или 1 секунда), то они удаляются из рассмотрения. Наличие это буфера критически важно, так как часто объекты бывают перекрыты полностью на короткий срок, во время которого сопоставление их траектории невозможно. Для таких траекторий происходит интерполяция их положения.

В работе на наборе данных MOT17 при использовании изображений размером \(800 \times 1440\) (оригинальный в наборе данных \(1080 \times 1920\)) получаются следующие показатели: MOTA -- 76.6; IDF1 -- 79.3; HOTA -- 63.1.

Для обучения сети детектора они использовали не только MOT17, но и CrowdHuman \cite{shao2018crowdhuman} с ETHZ \cite{ess2008mobile}.

